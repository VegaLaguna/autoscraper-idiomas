{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTEBOOK PARA APRENDER IDIOMAS\n",
    "\n",
    "Para aprender idiomas, en este caso el turco, la web de [www.turkishclass101.com](www.turkishclass101.com) propone aprender cada día una palabra nueva y usar dicha palabra en un par de frases. Además de la palabra en turco y dichas frases, también aparece su traducción.\n",
    "\n",
    "Vamos a scrapear la web yendo día a día a lo largo de un periodo de tiempo que nosotros determinemos para poder sacar un archivo Excel con una tabla donde aparezcan la lista de palabras, su traducción y las frases donde se usan (con su traducción igualmente).\n",
    "\n",
    "Vamos a hacer este scraping usando la librería [autoscraper](https://github.com/alirezamika/autoscraper), que facilita el web scraping al aprender las reglas del scraping de una URL dada y devuelve los elementos con una estructura similar de esa URL u otras URLs con contenido similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerías\n",
    "\n",
    "# Librerías estándar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Librería para medir el tiempo de ejecución\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librería para hacer el scraping\n",
    "\n",
    "# Si no la tenemos instalada: !pip install autoscraper\n",
    "from autoscraper import AutoScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST: Scrapear el día de hoy \n",
    "\n",
    "Antes de lanzar el código completo, pruebo a scrapear un solo día para ver como son los outputs que obtendré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabra en turco: ['indirim']\n",
      "Traducción al inglés: ['sale']\n",
      "Frases en turco: ['Ayakkabı bölümünde büyük bir indirimli satış var.', 'indirimli bir satışa bakmak', 'yüzde elli indirimli satış']\n",
      "Traducción al inglés: ['There is a big sale in the shoe department.', 'look for a sale', 'fifty percent off sale']\n"
     ]
    }
   ],
   "source": [
    "# Le hago el Autoscraper al día de hoy\n",
    "# y luego le pido que busque similares en los días anteriores\n",
    "\n",
    "# Defino la URL correspondiente a un día en concreto\n",
    "url_inicial = 'https://www.turkishclass101.com/turkish-phrases/02142021#wotd-widget'\n",
    "\n",
    "# Defino unas palabras de ejemplo\n",
    "palabra_tr = ['indirim']\n",
    "traduccion_en = ['sale']\n",
    "frases_tr = ['Ayakkabı bölümünde büyük bir indirimli satış var.']\n",
    "frases_en = ['There is a big sale in the shoe department.']\n",
    "\n",
    "# Inicializo los elementos que quiero scrapear\n",
    "scraper_palabra_tr = AutoScraper()\n",
    "scraper_traduccion_en = AutoScraper()\n",
    "scraper_frases_tr = AutoScraper()\n",
    "scraper_frases_en = AutoScraper()\n",
    "\n",
    "# Construyo la estructura de los elementos a scrapear\n",
    "result_palabra_tr = scraper_palabra_tr.build(url_inicial, palabra_tr)\n",
    "result_traduccion_en = scraper_traduccion_en.build(url_inicial, traduccion_en)\n",
    "result_frases_tr = scraper_frases_tr.build(url_inicial, frases_tr)\n",
    "result_frases_en = scraper_frases_en.build(url_inicial, frases_en)\n",
    "\n",
    "print('Palabra en turco:',result_palabra_tr)\n",
    "print('Traducción al inglés:',result_traduccion_en)\n",
    "print('Frases en turco:',result_frases_tr)\n",
    "print('Traducción al inglés:',result_frases_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTOMATIZACIÓN DEL PROCESO\n",
    "\n",
    "Primero separamos por pasos y luego juntaremos el código en una [función](#funcion) que recibirá como input el intervalo de días para el que queremos sacar las palabras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PASO 1: Seleccionar el intervalo temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos datos que van desde el 2020-01-01 hasta el 2020-12-31.\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.date(2020, 1, 1)\n",
    "end_date = datetime.date(2020, 12, 31)\n",
    "delta = datetime.timedelta(days=1)\n",
    "\n",
    "print('Tenemos datos que van desde el %s hasta el %s.' %(start_date, end_date))\n",
    "\n",
    "lista_fechas = []\n",
    "\n",
    "while start_date <= end_date:\n",
    "    # Convertimos las fechas al formato con el que entran en la URL\n",
    "    lista_fechas.append(start_date.strftime(\"%m%d%Y\"))\n",
    "    start_date += delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PASO 2: Scrapear las fechas seleccionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0 DE 366\n",
      "------------------------------ 30 DE 366\n",
      "------------------------------ 60 DE 366\n",
      "------------------------------ 90 DE 366\n",
      "------------------------------ 120 DE 366\n",
      "------------------------------ 150 DE 366\n",
      "------------------------------ 180 DE 366\n",
      "------------------------------ 210 DE 366\n",
      "------------------------------ 240 DE 366\n",
      "------------------------------ 270 DE 366\n",
      "------------------------------ 300 DE 366\n",
      "------------------------------ 330 DE 366\n",
      "------------------------------ 360 DE 366\n",
      "-----\n",
      "El proceso ha tardado 6.7 minutos.\n"
     ]
    }
   ],
   "source": [
    "lista_palabra_tr = []\n",
    "lista_trad_en = []\n",
    "lista_frases_tr = []\n",
    "lista_frases_en = []\n",
    "lista_fecha = []\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(lista_fechas)):\n",
    "    \n",
    "    # Hago print para ver el estado del loop cada 30 dias (aprox cada mes)\n",
    "    if i%1==0:\n",
    "        print(\"-\",end=\"\")\n",
    "    if i%30==0:\n",
    "        print(' %d DE %d' %(i, len(lista_fechas)))\n",
    "\n",
    "    \n",
    "    url = 'https://www.turkishclass101.com/turkish-phrases/'+lista_fechas[i]+'#wotd-widget'\n",
    "    \n",
    "    # Primero compruebo que hay el mismo número de frases en turco que en inglés\n",
    "    frases_tr = scraper_frases_tr.get_result_similar(url)\n",
    "    frases_en = scraper_frases_en.get_result_similar(url)\n",
    "\n",
    "    if len(frases_tr) == len(frases_en):\n",
    "        \n",
    "        # Si hay más de una frase, tengo que duplicar n veces la palabra en turco y en inglés\n",
    "        fechaN = [lista_fechas[i]]*len(frases_tr)\n",
    "        \n",
    "        palabra_tr = scraper_palabra_tr.get_result_similar(url)\n",
    "        palabra_trN = palabra_tr*len(frases_tr)\n",
    "        \n",
    "        trad_en = scraper_traduccion_en.get_result_similar(url)\n",
    "        trad_enN = trad_en*len(frases_tr)\n",
    "        \n",
    "        # Lo agrupamos en listas\n",
    "        lista_fecha.append(fechaN)\n",
    "        lista_palabra_tr.append(palabra_trN)\n",
    "        lista_trad_en.append(trad_enN)\n",
    "        lista_frases_tr.append(frases_tr)\n",
    "        lista_frases_en.append(frases_en)\n",
    "              \n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "# Desnidamos las listas de listas\n",
    "flat_lista_fecha = [item for sublist in lista_fecha for item in sublist]\n",
    "flat_lista_palabra_tr = [item for sublist in lista_palabra_tr for item in sublist]\n",
    "flat_lista_trad_en = [item for sublist in lista_trad_en for item in sublist]\n",
    "flat_lista_frases_tr = [item for sublist in lista_frases_tr for item in sublist]\n",
    "flat_lista_frases_en = [item for sublist in lista_frases_en for item in sublist]\n",
    "        \n",
    "print('\\nEl proceso ha tardado %.1f minutos.' %((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PASO 3: Crear un dataframe con los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Dia','Palabra_tr','Traduccion_en','Frase_tr','Frase_en'])\n",
    "df['Dia'] = pd.to_datetime(flat_lista_fecha, format=\"%m%d%Y\")\n",
    "df['Palabra_tr'] = flat_lista_palabra_tr\n",
    "df['Traduccion_en'] = flat_lista_trad_en\n",
    "df['Frase_tr'] = flat_lista_frases_tr\n",
    "df['Frase_en'] = flat_lista_frases_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dia</th>\n",
       "      <th>Palabra_tr</th>\n",
       "      <th>Traduccion_en</th>\n",
       "      <th>Frase_tr</th>\n",
       "      <th>Frase_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>karıştırmak</td>\n",
       "      <td>mix</td>\n",
       "      <td>Suyu ekle, ısıt ve karıştır.</td>\n",
       "      <td>Mix with water, heat and stir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>karıştırmak</td>\n",
       "      <td>mix</td>\n",
       "      <td>Unu suyla karıştırmalısın.</td>\n",
       "      <td>You need to mix the flour with water.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>karıştırmak</td>\n",
       "      <td>mix</td>\n",
       "      <td>suyla karıştırmak</td>\n",
       "      <td>mix with water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>üniversite</td>\n",
       "      <td>university</td>\n",
       "      <td>O ünlü bir üniversiteden tam burs kazandı.</td>\n",
       "      <td>He received a full scholarship from a famous u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>üniversite</td>\n",
       "      <td>university</td>\n",
       "      <td>eski üniversite</td>\n",
       "      <td>old university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>biyoloji</td>\n",
       "      <td>biology</td>\n",
       "      <td>Biyoloji, yaşayan canlıların incelenmesidir.</td>\n",
       "      <td>Biology is the study of living organisms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>biyoloji</td>\n",
       "      <td>biology</td>\n",
       "      <td>Biyoloji sınıfı</td>\n",
       "      <td>biology class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>İtalya</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Antik Roma İmparatorluğu`nun kalbi, modern I...</td>\n",
       "      <td>The heart of the ancient Roman empire was mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>İtalya</td>\n",
       "      <td>Italy</td>\n",
       "      <td>İtalya haritası</td>\n",
       "      <td>map of Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>İtalya</td>\n",
       "      <td>Italy</td>\n",
       "      <td>İtalya Başbakanı</td>\n",
       "      <td>Prime Minister of Italy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1186 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Dia    Palabra_tr Traduccion_en  \\\n",
       "0    2020-01-01  karıştırmak           mix   \n",
       "1    2020-01-01  karıştırmak           mix   \n",
       "2    2020-01-01  karıştırmak           mix   \n",
       "3    2020-01-02   üniversite    university   \n",
       "4    2020-01-02   üniversite    university   \n",
       "...         ...           ...           ...   \n",
       "1181 2020-12-30      biyoloji       biology   \n",
       "1182 2020-12-30      biyoloji       biology   \n",
       "1183 2020-12-31       İtalya         Italy   \n",
       "1184 2020-12-31       İtalya         Italy   \n",
       "1185 2020-12-31       İtalya         Italy   \n",
       "\n",
       "                                               Frase_tr  \\\n",
       "0                         Suyu ekle, ısıt ve karıştır.   \n",
       "1                           Unu suyla karıştırmalısın.   \n",
       "2                                    suyla karıştırmak   \n",
       "3         O ünlü bir üniversiteden tam burs kazandı.   \n",
       "4                                      eski üniversite   \n",
       "...                                                 ...   \n",
       "1181      Biyoloji, yaşayan canlıların incelenmesidir.   \n",
       "1182                                    Biyoloji sınıfı   \n",
       "1183  Antik Roma İmparatorluğu`nun kalbi, modern I...   \n",
       "1184                                   İtalya haritası   \n",
       "1185                                 İtalya Başbakanı   \n",
       "\n",
       "                                               Frase_en  \n",
       "0                        Mix with water, heat and stir.  \n",
       "1                 You need to mix the flour with water.  \n",
       "2                                        mix with water  \n",
       "3     He received a full scholarship from a famous u...  \n",
       "4                                        old university  \n",
       "...                                                 ...  \n",
       "1181          Biology is the study of living organisms.  \n",
       "1182                                      biology class  \n",
       "1183  The heart of the ancient Roman empire was mode...  \n",
       "1184                                       map of Italy  \n",
       "1185                            Prime Minister of Italy  \n",
       "\n",
       "[1186 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PASO 4: Guardamos el csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_turco2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='funcion'></a>\n",
    "##### DEFINIMOS LA FUNCIÓN QUE ENGLOBA LOS PASOS ANTERIORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_turco(fecha_inicial, fecha_final):\n",
    "    \n",
    "    #PASO 1: Seleccionar el intervalo temporal\n",
    "    start_date = datetime.datetime.strptime(fecha_inicial, '%d-%m-%Y').date()\n",
    "    end_date = datetime.datetime.strptime(fecha_final, '%d-%m-%Y').date()\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    \n",
    "    lista_fechas = []\n",
    "    while start_date <= end_date:\n",
    "        # Convertimos las fechas al formato con el que entran en la URL\n",
    "        lista_fechas.append(start_date.strftime(\"%m%d%Y\"))\n",
    "        start_date += delta\n",
    "        \n",
    "        \n",
    "    # PASO 2: Scrapear las fechas seleccionadas\n",
    "    lista_palabra_tr = []\n",
    "    lista_trad_en = []\n",
    "    lista_frases_tr = []\n",
    "    lista_frases_en = []\n",
    "    lista_fecha = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(len(lista_fechas)):\n",
    "        \n",
    "        # Hago print para ver el estado del loop cada 30 dias (aprox cada mes)\n",
    "        if i%1==0:\n",
    "            print(\"-\",end=\"\")\n",
    "        if i%30==0:\n",
    "            print(' %d DE %d' %(i, len(lista_fechas)))\n",
    "\n",
    "        url = 'https://www.turkishclass101.com/turkish-phrases/'+lista_fechas[i]+'#wotd-widget'\n",
    "\n",
    "        # Primero compruebo que hay el mismo número de frases en turco que en inglés\n",
    "        frases_tr = scraper_frases_tr.get_result_similar(url)\n",
    "        frases_en = scraper_frases_en.get_result_similar(url)\n",
    "\n",
    "        if len(frases_tr) == len(frases_en):\n",
    "\n",
    "            # Si hay más de una frase, tengo que duplicar n veces la palabra en turco y en inglés\n",
    "            fechaN = [lista_fechas[i]]*len(frases_tr)\n",
    "\n",
    "            palabra_tr = scraper_palabra_tr.get_result_similar(url)\n",
    "            palabra_trN = palabra_tr*len(frases_tr)\n",
    "\n",
    "            trad_en = scraper_traduccion_en.get_result_similar(url)\n",
    "            trad_enN = trad_en*len(frases_tr)\n",
    "\n",
    "            # Lo agrupamos en listas\n",
    "            lista_fecha.append(fechaN)\n",
    "            lista_palabra_tr.append(palabra_trN)\n",
    "            lista_trad_en.append(trad_enN)\n",
    "            lista_frases_tr.append(frases_tr)\n",
    "            lista_frases_en.append(frases_en)\n",
    "\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Desnidamos las listas de listas\n",
    "    flat_lista_fecha = [item for sublist in lista_fecha for item in sublist]\n",
    "    flat_lista_palabra_tr = [item for sublist in lista_palabra_tr for item in sublist]\n",
    "    flat_lista_trad_en = [item for sublist in lista_trad_en for item in sublist]\n",
    "    flat_lista_frases_tr = [item for sublist in lista_frases_tr for item in sublist]\n",
    "    flat_lista_frases_en = [item for sublist in lista_frases_en for item in sublist]\n",
    "    print('\\nEl proceso ha tardado %.1f minutos.' %((time.time()-start_time)/60))\n",
    "    \n",
    "    \n",
    "    # PASO 3: Crear un dataframe con los resultados\n",
    "    df = pd.DataFrame(columns=['Dia','Palabra_tr','Traduccion_en','Frase_tr','Frase_en'])\n",
    "    df['Dia'] = pd.to_datetime(flat_lista_fecha, format=\"%m%d%Y\")\n",
    "    df['Palabra_tr'] = flat_lista_palabra_tr\n",
    "    df['Traduccion_en'] = flat_lista_trad_en\n",
    "    df['Frase_tr'] = flat_lista_frases_tr\n",
    "    df['Frase_en'] = flat_lista_frases_en\n",
    "    \n",
    "    \n",
    "    # PASO 4: Guardamos el csv\n",
    "    df.to_csv('df_turco2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0 DE 10\n",
      "---------\n",
      "El proceso ha tardado 0.2 minutos.\n"
     ]
    }
   ],
   "source": [
    "scraping_turco('01-02-2021', '10-02-2021')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
